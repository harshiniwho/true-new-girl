{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new-girl.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP7mev7xy2zaF4IHY2XwOEy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/harshiniwho/true-new-girl/blob/master/new_girl.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp-AylDr4BKt"
      },
      "source": [
        "# New Girl References\n",
        "As a New Girl fan and on my fourth rewatch, I excessively screenshot my favourite stills. Unlike other more popular shows the resources to catch the New Girl references is hard, so this is an attempt to compile, tag my collection of screenshots from the show.\n",
        "My screenshots are from watching the show with subtitles, so I will be first tagging the images based on the content in each of them.\n",
        "Second I will be tagging them via who is in the frame.\n",
        "Third I will be tagging some of them personally with some keywords (a long task, but do not underestimate the fangirl in me!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpFHnK805Dzl"
      },
      "source": [
        "# Install Libraries / Dependencies\n",
        "\n",
        "Running and testing this on Google Colab GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R4pIyTw91WQ",
        "outputId": "759cb657-54f4-48ca-cbe4-63d5f45300d5"
      },
      "source": [
        "! apt install tesseract-ocr\n",
        "! apt install libtesseract-dev\n",
        "! sudo apt install tesseract-ocr\n",
        "! pip install Pillow\n",
        "! pip install pytesseract\n",
        "import pytesseract\n",
        "from google.colab import files\n",
        "from io import BytesIO\n",
        "from PIL import Image,ImageFilter\n",
        "#from google.colab import drive\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install tesseract\n",
        "!pip install face_recognition\n",
        "!pip install fer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 2s (3,068 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 160837 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 2 newly installed, 0 to remove and 39 not upgraded.\n",
            "Need to get 2,755 kB of archives.\n",
            "After this operation, 13.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libleptonica-dev amd64 1.75.3-3 [1,308 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libtesseract-dev amd64 4.00~git2288-10f4998a-2 [1,447 kB]\n",
            "Fetched 2,755 kB in 1s (1,889 kB/s)\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "(Reading database ... 160884 files and directories currently installed.)\n",
            "Preparing to unpack .../libleptonica-dev_1.75.3-3_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.75.3-3) ...\n",
            "Selecting previously unselected package libtesseract-dev.\n",
            "Preparing to unpack .../libtesseract-dev_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking libtesseract-dev (4.00~git2288-10f4998a-2) ...\n",
            "Setting up libleptonica-dev (1.75.3-3) ...\n",
            "Setting up libtesseract-dev (4.00~git2288-10f4998a-2) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Collecting pytesseract\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/c9/d6e8903482bd6fb994c32722831d15842dd8b614f94ad9ca735807252671/pytesseract-0.3.8.tar.gz\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.8-py2.py3-none-any.whl size=14071 sha256=f76659e85b96f989e33c55ffbcb7b8a524e7e5e3ee095dbe775dd3a6609bfe67\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/66/45/88bf1b2d428817a006944b9730b27d6861b776e05a9e262bd4\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.8\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.7/dist-packages (0.3.8)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Collecting tesseract\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8d/b7/c4fae9af5842f69d9c45bf1195a94aec090628535c102894552a7a7dbe6c/tesseract-0.1.3.tar.gz (45.6MB)\n",
            "\u001b[K     |████████████████████████████████| 45.6MB 66kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: tesseract\n",
            "  Building wheel for tesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tesseract: filename=tesseract-0.1.3-cp37-none-any.whl size=45562571 sha256=917432fe5affd06326d2cac8e7d41ed8a38c6ec76b46e5f85ab27f663d1ca853\n",
            "  Stored in directory: /root/.cache/pip/wheels/82/1f/d9/24797b123379e4ea9511cf660835468b62dad609634cad2aba\n",
            "Successfully built tesseract\n",
            "Installing collected packages: tesseract\n",
            "Successfully installed tesseract-0.1.3\n",
            "Collecting face_recognition\n",
            "  Downloading https://files.pythonhosted.org/packages/1e/95/f6c9330f54ab07bfa032bf3715c12455a381083125d8880c43cbe76bb3d0/face_recognition-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cf/3b/4fd8c534f6c0d1b80ce0973d01331525538045084c73c153ee6df20224cf/face_recognition_models-0.3.0.tar.gz (100.1MB)\n",
            "\u001b[K     |████████████████████████████████| 100.2MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566184 sha256=1e11e1689a8dd0614cc3f57425ae1b92ee54e402de431d738f30ad1d214b0db6\n",
            "  Stored in directory: /root/.cache/pip/wheels/d2/99/18/59c6c8f01e39810415c0e63f5bede7d83dfb0ffc039865465f\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n",
            "Collecting fer\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/8b/bdfa0699e0a2168290a53ebfc1e0a569c99d2ad47668d06db15efac998e2/fer-21.0.2-py3-none-any.whl (810kB)\n",
            "\u001b[K     |████████████████████████████████| 819kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fer) (3.2.2)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from fer) (4.1.2.30)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fer) (1.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fer) (2.23.0)\n",
            "Collecting mtcnn>=0.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/d1/2a4269e387edb97484157b872fa8a1953b53dcafbe4842a1967f549ac5ea/mtcnn-0.1.1-py3-none-any.whl (2.3MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 37.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow~=2.0 in /usr/local/lib/python3.7/dist-packages (from fer) (2.5.0)\n",
            "Requirement already satisfied: keras==2.4.3 in /usr/local/lib/python3.7/dist-packages (from fer) (2.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (0.10.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fer) (2018.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (2021.5.30)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn>=0.1.1->fer) (4.1.2.30)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (0.36.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (2.5.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (3.1.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (0.12.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (2.5.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (3.3.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (1.12.1)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (3.17.3)\n",
            "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (2.5.0.dev2021032900)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (1.12)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (1.1.2)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (1.34.1)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.0->fer) (3.7.4.3)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3->fer) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from keras==2.4.3->fer) (3.13)\n",
            "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow~=2.0->fer) (1.5.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.0->fer) (1.32.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.0->fer) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.0->fer) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.0->fer) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.0->fer) (57.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.0->fer) (0.4.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow~=2.0->fer) (1.8.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.0->fer) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.0->fer) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.0->fer) (4.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow~=2.0->fer) (4.6.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow~=2.0->fer) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow~=2.0->fer) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->tensorflow~=2.0->fer) (3.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow~=2.0->fer) (3.1.1)\n",
            "Installing collected packages: mtcnn, fer\n",
            "Successfully installed fer-21.0.2 mtcnn-0.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwxxFuWrF7jU"
      },
      "source": [
        "# Step 0: Before the loop!\n",
        "We will be storing all the data in a file and looping for each image. Will first be adding the common steps here outside the loop. Probably will structure this code differently as files instead of a notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKpcbWoiGNyT"
      },
      "source": [
        "# Let us create a file\n",
        "with open('new-girl-dataset.json', 'w') as fp:\n",
        "    pass"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ8cacYZJYIb"
      },
      "source": [
        "We will need the mapping of all the characters, this is needed to be run only once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Geu_LiJkUq"
      },
      "source": [
        "import numpy\n",
        "import cv2\n",
        "import face_recognition"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whAtLYn8JeMy"
      },
      "source": [
        "#mapping references, this will have to be moved out so that this does not repeat\n",
        "jess1_img = face_recognition.load_image_file('jess1.jpg')\n",
        "jess1_encoding = face_recognition.face_encodings(jess1_img)[0]\n",
        "\n",
        "jess2_img = face_recognition.load_image_file('jess2.png')\n",
        "jess2_encoding = face_recognition.face_encodings(jess2_img)[0]\n",
        "\n",
        "cece_img = face_recognition.load_image_file('cece.jpg')\n",
        "cece_encoding = face_recognition.face_encodings(cece_img)[0]\n",
        "\n",
        "nick_img = face_recognition.load_image_file('nick.jpg')\n",
        "nick_encoding = face_recognition.face_encodings(nick_img)[0]\n",
        "\n",
        "schmidt_img = face_recognition.load_image_file('schmidt.jpg')\n",
        "schmidt_encoding = face_recognition.face_encodings(schmidt_img)[0]\n",
        "\n",
        "winston_img = face_recognition.load_image_file('winston.jpg')\n",
        "winston_encoding = face_recognition.face_encodings(winston_img)[0]\n",
        "\n",
        "character_encodings = [jess1_encoding, jess2_encoding, cece_encoding, \n",
        "                       nick_encoding, schmidt_encoding, winston_encoding]\n",
        "character_names = ['jess', 'jess', 'cece', 'nick', 'schmidt', 'winston']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVUm0IpR_rBU"
      },
      "source": [
        "# Loop starts here: Dataset structure\n",
        "The below code will iterate over every image, so creating a dict for every image with the fields: 'image_name', 'subtitles', 'characters', 'emotions', 'optional_tags'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq6wXq7SBVWF"
      },
      "source": [
        "data = {}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0rbkkLvBfXz"
      },
      "source": [
        "data['image_name'] = r'test3.png'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIZW-sza5J-u"
      },
      "source": [
        "# Step 1: Tagging images by the subtitles\n",
        "\n",
        "Right off the bat issues, the OTT platform log can be cropped so that isn't read. Second, can crop the image to just the bottom half for it to focus on just the text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO3dNV8uUJUH"
      },
      "source": [
        "Cropping the image to make things simpler"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ7StJs5T-9V"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "# add the image\n",
        "img = Image.open(data['image_name'])\n",
        "\n",
        "width, height = img.size\n",
        "\n",
        "# cropping image, removing top half\n",
        "img_cropped = img.crop((0, height/2, width, height))\n",
        " \n",
        "# Shows the image in image viewer\n",
        "# img_cropped.show()\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohHyj3GYUG3d"
      },
      "source": [
        "Reading the image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okMsoWS65QaN",
        "outputId": "5a66062e-8092-4608-b2fd-4184a5139deb"
      },
      "source": [
        "# setting the tesseract cmd\n",
        "pytesseract.pytesseract.tesseract_cmd = (\n",
        "    r'/usr/bin/tesseract'\n",
        ")\n",
        "  \n",
        "# Passing the image object to image_to_string() function\n",
        "# This function will extract the text from the image\n",
        "text = pytesseract.image_to_string(img_cropped)\n",
        "  \n",
        "# Displaying the extracted text\n",
        "print(text[:-1])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n",
            " \n",
            " \n",
            "\n",
            " \n",
            "\n",
            "You can forgive alot\n",
            "during wartime.\n",
            "\n",
            " \n",
            "    \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55QJqdOxml3e"
      },
      "source": [
        "Clean line, replace new lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ngzUBeQcmNmN",
        "outputId": "09b9583b-26f4-4ad5-ad19-f6540dc887e4"
      },
      "source": [
        "text[:-1].strip().replace('\\n', ' ')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'You can forgive alot during wartime.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Dhdh2IYDA11"
      },
      "source": [
        "data['subtitles'] = text[:-1].strip().replace('\\n', ' ')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o0gCgyYmtfP"
      },
      "source": [
        "# Step 2: Identifying characters in the image\n",
        "Another way I would want to quote them is by the character in the image, who is usually in the frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "317mplwCnCIx"
      },
      "source": [
        "We will refer the mapping of the main characters (and side), from the beginning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QH__egvwntHW"
      },
      "source": [
        "import numpy\n",
        "import cv2\n",
        "import face_recognition"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7rPapuNnMjq"
      },
      "source": [
        "Now, let us see if the current image has one of these characters in an identifiable form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0sBekwlwZcS"
      },
      "source": [
        "load_img = face_recognition.load_image_file(data['image_name'])\n",
        "img_encoding = face_recognition.face_encodings(load_img)[0]\n",
        "match = face_recognition.compare_faces(character_encodings, img_encoding)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgYzFVmIzX3u",
        "outputId": "335617f5-c8b9-4a30-cf3d-68fa77eef9bd"
      },
      "source": [
        "match"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[False, True, False, False, False, False]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "japU5_YQDHLq"
      },
      "source": [
        "characters = []\n",
        "for i in range(len(character_encodings)):\n",
        "  if match[i]:\n",
        "    characters.append(character_names[i])\n",
        "data['characters'] = characters"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92xgj0UKaBbp",
        "outputId": "3691bc11-04a0-4326-f51f-02f637fe3067"
      },
      "source": [
        "characters"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['jess']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnikmV16nYmf"
      },
      "source": [
        "# Step 3: Meta info / other tags\n",
        "If I wanted to manually add tags like which season, or maybe find a way to use the images themselves to create some tags for them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ewwNODw55s3Z"
      },
      "source": [
        "Let us try to see what the emotion here looks like (to do: maybe using the same libraries for the previous use case as well)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X9X4B-J64iM4",
        "outputId": "1e78982b-86e6-4e2e-e45b-b4023d80c8f4"
      },
      "source": [
        "from fer import FER\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#TODO: this works only with jpgs, to investigate\n",
        "img = plt.imread('nick.jpg')\n",
        "detector = FER(mtcnn=True)\n",
        "detected_emotions = detector.detect_emotions(img)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpLER7V0-uBr",
        "outputId": "f3f877fb-ab3a-4a1e-de2e-6c6ef635578c"
      },
      "source": [
        "detected_emotions[0]['emotions']"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'angry': 0.0,\n",
              " 'disgust': 0.0,\n",
              " 'fear': 0.0,\n",
              " 'happy': 1.0,\n",
              " 'neutral': 0.0,\n",
              " 'sad': 0.0,\n",
              " 'surprise': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni06_QxFDv_b",
        "outputId": "a9a91ffa-9643-4160-9d3f-3487670ac026"
      },
      "source": [
        "# including the emotions above the threshold of 70%\n",
        "emotions = []\n",
        "emotion_map = detected_emotions[0]['emotions']\n",
        "for emotion in emotion_map.keys():\n",
        "  if emotion_map[emotion] > 0.7:\n",
        "    emotions.append(emotion)\n",
        "data['emotions'] = emotions"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "angry\n",
            "disgust\n",
            "fear\n",
            "happy\n",
            "sad\n",
            "surprise\n",
            "neutral\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WwtywYpcYKB",
        "outputId": "b295e7a6-f376-4a3a-e4df-5128dffb125e"
      },
      "source": [
        "data['emotions']"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['happy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ_8DqG254kn"
      },
      "source": [
        "Let us look at the filename to figure out when I screenshotted it for linking to the season,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQAjsPqP84J4"
      },
      "source": [
        "# TODO: will have to figure out when these timestamps are\n",
        "data['season'] = 2"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSYQe5fw6FU6"
      },
      "source": [
        "Finally, if I have any tags I would like to add!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WJIJj-88-eZ"
      },
      "source": [
        "# ok let us say I will view and add one at a time, let us see if I can come up with a better way"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBF5FI9QFoSn"
      },
      "source": [
        "# Step 4: Append to dataset\n",
        "Let us for now put these values in a file with each dict as a row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bymQwWPPcb32",
        "outputId": "cc7d7911-8050-4c48-a4d7-8fdc1ed7b7ca"
      },
      "source": [
        "data"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'characters': ['jess'],\n",
              " 'emotions': ['happy'],\n",
              " 'image_name': 'test3.png',\n",
              " 'season': 2,\n",
              " 'subtitles': 'You can forgive alot during wartime.'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5fPyQkcF3Y2"
      },
      "source": [
        "import json\n",
        "with open('new-girl-dataset.json', 'w') as fp:\n",
        "    json.dump(data, fp)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mowClJ0CAbV3"
      },
      "source": [
        "# Future Ideas\n",
        "So far I am treating each image separately, there is more info we could do by analysing them together - for example which episode."
      ]
    }
  ]
}