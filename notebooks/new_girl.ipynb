{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "new-girl.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mp-AylDr4BKt"
      },
      "source": [
        "# New Girl References\n",
        "As a New Girl fan and on my fourth rewatch, I excessively screenshot my favourite stills. Unlike other more popular shows the resources to catch the New Girl references is hard, so this is an attempt to compile, tag my collection of screenshots from the show.\n",
        "My screenshots are from watching the show with subtitles, so I will be first tagging the images based on the content in each of them.\n",
        "Second I will be tagging them via who is in the frame.\n",
        "Third I will be tagging some of them personally with some keywords (a long task, but do not underestimate the fangirl in me!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mpFHnK805Dzl"
      },
      "source": [
        "# Install Libraries / Dependencies\n",
        "\n",
        "Running and testing this on Google Colab GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R4pIyTw91WQ",
        "outputId": "73f4a5cd-b336-4136-a0a3-9796f734172e"
      },
      "source": [
        "! apt install tesseract-ocr\n",
        "! apt install libtesseract-dev\n",
        "! sudo apt install tesseract-ocr\n",
        "! pip install Pillow\n",
        "! pip install pytesseract\n",
        "import pytesseract\n",
        "from google.colab import files\n",
        "from io import BytesIO\n",
        "from PIL import Image,ImageFilter\n",
        "!sudo apt install tesseract-ocr\n",
        "!pip install pytesseract\n",
        "!pip install tesseract\n",
        "!pip install face_recognition\n",
        "!pip install fer"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 4,795 kB of archives.\n",
            "After this operation, 15.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-eng all 4.00~git24-0e00fe6-1.2 [1,588 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr-osd all 4.00~git24-0e00fe6-1.2 [2,989 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/universe amd64 tesseract-ocr amd64 4.00~git2288-10f4998a-2 [218 kB]\n",
            "Fetched 4,795 kB in 1s (3,726 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 155013 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_4.00~git24-0e00fe6-1.2_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Setting up tesseract-ocr-osd (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr-eng (4.00~git24-0e00fe6-1.2) ...\n",
            "Setting up tesseract-ocr (4.00~git2288-10f4998a-2) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libleptonica-dev\n",
            "The following NEW packages will be installed:\n",
            "  libleptonica-dev libtesseract-dev\n",
            "0 upgraded, 2 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 2,755 kB of archives.\n",
            "After this operation, 13.8 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libleptonica-dev amd64 1.75.3-3 [1,308 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/universe amd64 libtesseract-dev amd64 4.00~git2288-10f4998a-2 [1,447 kB]\n",
            "Fetched 2,755 kB in 1s (2,340 kB/s)\n",
            "Selecting previously unselected package libleptonica-dev.\n",
            "(Reading database ... 155060 files and directories currently installed.)\n",
            "Preparing to unpack .../libleptonica-dev_1.75.3-3_amd64.deb ...\n",
            "Unpacking libleptonica-dev (1.75.3-3) ...\n",
            "Selecting previously unselected package libtesseract-dev.\n",
            "Preparing to unpack .../libtesseract-dev_4.00~git2288-10f4998a-2_amd64.deb ...\n",
            "Unpacking libtesseract-dev (4.00~git2288-10f4998a-2) ...\n",
            "Setting up libleptonica-dev (1.75.3-3) ...\n",
            "Setting up libtesseract-dev (4.00~git2288-10f4998a-2) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (7.1.2)\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.8.tar.gz (14 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Building wheels for collected packages: pytesseract\n",
            "  Building wheel for pytesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytesseract: filename=pytesseract-0.3.8-py2.py3-none-any.whl size=14072 sha256=330facfed58edb14ae5301f26df525eb1d43267f5f4bef0271ce42e9daec6ec2\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/89/b9/3f11250225d0f90e5454fcc30fd1b7208db226850715aa9ace\n",
            "Successfully built pytesseract\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.8\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.00~git2288-10f4998a-2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.7/dist-packages (0.3.8)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from pytesseract) (7.1.2)\n",
            "Collecting tesseract\n",
            "  Downloading tesseract-0.1.3.tar.gz (45.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 45.6 MB 51 kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: tesseract\n",
            "  Building wheel for tesseract (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tesseract: filename=tesseract-0.1.3-py3-none-any.whl size=45562569 sha256=2bdbec56e169a16be41e907f4e2af91a82ac9a7095b2c0000bb443b29b12ebe0\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/3f/af/2f732560b9c4e51dd131bcbc6b7466a3124d15ab3fd393f85a\n",
            "Successfully built tesseract\n",
            "Installing collected packages: tesseract\n",
            "Successfully installed tesseract-0.1.3\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting face-recognition-models>=0.3.0\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 100.1 MB 23 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from face_recognition) (1.19.5)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.7/dist-packages (from face_recognition) (19.18.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from face_recognition) (7.1.2)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566185 sha256=9952b0a8ce35330686de7a777f820f031c0138e8c55a8f05e49e22b745cf51fe\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/81/3c/884bcd5e1c120ff548d57c2ecc9ebf3281c9a6f7c0e7e7947a\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face-recognition\n",
            "Successfully installed face-recognition-1.3.0 face-recognition-models-0.3.0\n",
            "Collecting fer\n",
            "  Downloading fer-21.0.4-py3-none-any.whl (810 kB)\n",
            "\u001b[K     |████████████████████████████████| 810 kB 5.6 MB/s \n",
            "\u001b[?25hCollecting mtcnn>=0.1.1\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 33.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.7/dist-packages (from fer) (4.1.2.30)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from fer) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from fer) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fer) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fer) (2.23.0)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from fer) (2.6.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from mtcnn>=0.1.1->fer) (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python>=4.1.0->mtcnn>=0.1.1->fer) (1.19.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->fer) (2.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->fer) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->fer) (2018.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fer) (2.10)\n",
            "Installing collected packages: mtcnn, fer\n",
            "Successfully installed fer-21.0.4 mtcnn-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwxxFuWrF7jU"
      },
      "source": [
        "# Step 0: Before the loop!\n",
        "We will be storing all the data in a file and looping for each image. Will first be adding the common steps here outside the loop. Probably will structure this code differently as files instead of a notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKpcbWoiGNyT"
      },
      "source": [
        "# Let us create a file\n",
        "with open('new-girl-dataset.json', 'w') as fp:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQ8cacYZJYIb"
      },
      "source": [
        "# Characters on the show\n",
        "We will need the mapping of all the characters, this is needed to be run only once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Geu_LiJkUq"
      },
      "source": [
        "import cv2\n",
        "import face_recognition\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vJk--4SLdji"
      },
      "source": [
        "# encoding one image\n",
        "def face_encode(image_name):\n",
        "  char_img = face_recognition.load_image_file('characters/' + image_name)\n",
        "  char_encoding = face_recognition.face_encodings(char_img)[0]\n",
        "  return char_encoding"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iO0su1q3Kff3"
      },
      "source": [
        "from numpy import genfromtxt\n",
        "# saving all encodings to file and reading for later executions\n",
        "def write_to_file(data, filename):\n",
        "    with open('encodings/' + filename + '.csv', 'wb') as f:\n",
        "        np.savetxt(f, data, delimiter=\",\")\n",
        "\n",
        "\n",
        "def read_from_file(filename):\n",
        "    data = genfromtxt('encodings/' + filename, delimiter=',')\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib_8-QbXKzKr"
      },
      "source": [
        "# iterate through a dir with all character images\n",
        "import os\n",
        "image_files = os.listdir('characters')\n",
        "characters_order = []\n",
        "character_encodings = []\n",
        "for image_file in image_files:\n",
        "  try:\n",
        "    charname = image_file[:-4]\n",
        "    print(\"on character \" + charname)\n",
        "    char_encoding = face_encode(image_file)\n",
        "    write_to_file(char_encoding, charname)\n",
        "    character_encodings.append(char_encoding)\n",
        "    characters_order.append(charname)\n",
        "  except:\n",
        "    print(\"oops skipping \" + image_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTX5mjxVPBCR",
        "outputId": "bd2bbb6d-5140-4430-97f4-d3e4dce7ede1"
      },
      "source": [
        "len(characters_order)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RqBbIBtmYWqX"
      },
      "source": [
        "All images were from the fandom wiki:\n",
        "https://newgirl.fandom.com/wiki/Category:Characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkMDD8-EV4OX"
      },
      "source": [
        "# Getting all files in a folder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mck7ooYBV-6N"
      },
      "source": [
        "# getting all images for one batch folder\n",
        "import json\n",
        "with open('out.json', 'r') as f:\n",
        "  files = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_EnRUybaJ8v",
        "outputId": "a13e8d8b-9aff-4f3d-915c-ceadf74017a8"
      },
      "source": [
        "len(files['resources'])\n",
        "for file in files['resources']:\n",
        "  print(file)\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'asset_id': '5f5595bfa51b651a5b8b0fae313c048c', 'public_id': 'new-girl/batch50/Screenshot2021-07-16at2.10.57PM_v5syiz', 'folder': 'new-girl/batch50', 'filename': 'Screenshot2021-07-16at2.10.57PM_v5syiz', 'display_name': 'Screenshot2021-07-16at2.10.57PM_v5syiz', 'format': 'jpg', 'version': 1632505760, 'resource_type': 'image', 'type': 'upload', 'created_at': '2021-09-24T17:49:20+00:00', 'uploaded_at': '2021-09-24T17:49:20+00:00', 'bytes': 260567, 'backup_bytes': 0, 'width': 3360, 'height': 2100, 'aspect_ratio': 1.6, 'pixels': 7056000, 'url': 'http://res.cloudinary.com/dw4ieof1c/image/upload/v1632505760/new-girl/batch50/Screenshot2021-07-16at2.10.57PM_v5syiz.jpg', 'secure_url': 'https://res.cloudinary.com/dw4ieof1c/image/upload/v1632505760/new-girl/batch50/Screenshot2021-07-16at2.10.57PM_v5syiz.jpg', 'status': 'active', 'access_mode': 'public', 'access_control': None, 'etag': '7e4e714ac9550a6ccac0b4993fc16274', 'created_by': {'access_key': '116337224483685', 'custom_id': 'harshiniramanujam@gmail.com', 'external_id': '4051f144e4c3e638ad9d40d486af88'}, 'uploaded_by': {'access_key': '116337224483685', 'custom_id': 'harshiniramanujam@gmail.com', 'external_id': '4051f144e4c3e638ad9d40d486af88'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVUm0IpR_rBU"
      },
      "source": [
        "# Loop starts here: Dataset structure\n",
        "The below code will iterate over every image, so creating a dict for every image with the fields: 'image_name', 'subtitles', 'characters', 'emotions', 'optional_tags'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PlmjxU5Xjvci"
      },
      "source": [
        "# fetch image from source\n",
        "import requests\n",
        "response = requests.get(\"https://res.cloudinary.com/dw4ieof1c/image/upload/v1632050494/new-girl/batch20/Screenshot2021-07-07at11.15.22PM_tkl8tu.jpg\")\n",
        "\n",
        "file = open(\"sample_image.jpg\", \"wb\")\n",
        "file.write(response.content)\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq6wXq7SBVWF"
      },
      "source": [
        "data = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0rbkkLvBfXz"
      },
      "source": [
        "data['filename'] = r'Screenshot2021-09-17at6.29.04PM_a4vitu.jpg'\n",
        "data['imageLink'] = r\"https://res.cloudinary.com/dw4ieof1c/image/upload/v1632050494/new-girl/batch20/Screenshot2021-07-07at11.15.22PM_tkl8tu.jpg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIZW-sza5J-u"
      },
      "source": [
        "# Step 1: Tagging images by the subtitles\n",
        "\n",
        "Right off the bat issues, the OTT platform log can be cropped so that isn't read. Second, can crop the image to just the bottom half for it to focus on just the text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DO3dNV8uUJUH"
      },
      "source": [
        "Cropping the image to make things simpler (could crop more than just the top half)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQ7StJs5T-9V"
      },
      "source": [
        "from PIL import Image\n",
        "\n",
        "# add the image\n",
        "img = Image.open(data['filename'])\n",
        "\n",
        "width, height = img.size\n",
        "\n",
        "# cropping image, removing top half\n",
        "img_cropped = img.crop((0, height/2, width, height))\n",
        " \n",
        "# Shows the image in image viewer\n",
        "img_cropped.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohHyj3GYUG3d"
      },
      "source": [
        "Reading the image using pytessaract which is a wrapper around tessaract (I think of Loki every time I hear tessaract). I am not doing anything to clean the pictures since they are high resolution and the text is very clear."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okMsoWS65QaN",
        "outputId": "1f37d5ea-667a-474a-e8c6-a1c1d1d6db7d"
      },
      "source": [
        "# setting the tesseract cmd\n",
        "pytesseract.pytesseract.tesseract_cmd = (\n",
        "    r'/usr/bin/tesseract'\n",
        ")\n",
        "  \n",
        "# Passing the image object to image_to_string() function\n",
        "# This function will extract the text from the image\n",
        "text = pytesseract.image_to_string(img_cropped)\n",
        "  \n",
        "# Displaying the extracted text\n",
        "print(text[:-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55QJqdOxml3e"
      },
      "source": [
        "Clean line, replace new lines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ngzUBeQcmNmN",
        "outputId": "55f43354-d137-4f75-c57e-450dcfbdadf3"
      },
      "source": [
        "text[:-1].strip().replace('\\n', ' ').replace('|', 'I')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YP00azCZrvW"
      },
      "source": [
        "Since there are screenshots of characters' pure reactions with no text, I will assign those as NA."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Dhdh2IYDA11"
      },
      "source": [
        "subtitles = text[:-1].strip().replace('\\n', ' ').replace('|', 'I')\n",
        "if subtitles:\n",
        "  data['subtitle'] = subtitles\n",
        "else:\n",
        "  data['subtitle'] = 'NA'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pB8NFFdaTeQ"
      },
      "source": [
        "Final note: In case the text is read wrong, I will think about word sense check. However, characters in the show also use words that do not exist, so will come back to this."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o0gCgyYmtfP"
      },
      "source": [
        "# Step 2: Identifying characters in the image\n",
        "Another way I would want to quote them is by the character in the image, who is usually in the frame"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "317mplwCnCIx"
      },
      "source": [
        "We will refer the mapping of the main characters (and side), from the beginning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuZnMD4OheqY"
      },
      "source": [
        "# construct map from file encodings\n",
        "characters_order = []\n",
        "character_encodings = []\n",
        "for filename in os.listdir('encodings'):\n",
        "  try:\n",
        "    character_encodings.append(read_from_file(filename))\n",
        "    characters_order.append(filename[:-4])\n",
        "  except:\n",
        "    print('oops could not read encoding from ' + filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7-NFyzaieLk",
        "outputId": "e2b9e92d-5782-4822-b6ea-72ac80ef9bcb"
      },
      "source": [
        "len(characters_order)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "78"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7rPapuNnMjq"
      },
      "source": [
        "Now, let us see if the current image has one of these characters in an identifiable form"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVZJDGIgkv16"
      },
      "source": [
        "def check_for_characters(match):\n",
        "  characters = []\n",
        "  for i in range(len(character_encodings)):\n",
        "    if match[i]:\n",
        "      characters.append(characters_order[i])\n",
        "  return characters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0sBekwlwZcS"
      },
      "source": [
        "load_img = face_recognition.load_image_file(data['filename'])\n",
        "\n",
        "img_encoding = face_recognition.face_encodings(load_img)\n",
        "characters = []\n",
        "for face_encoding in img_encoding:\n",
        "  if (face_encoding.any()):\n",
        "    match = face_recognition.compare_faces(character_encodings, face_encoding)\n",
        "    # ok make this check more efficient\n",
        "    chars = check_for_characters(match)\n",
        "    characters.extend(chars)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "japU5_YQDHLq"
      },
      "source": [
        "data['characters'] = characters"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5qfNP1TmsEH",
        "outputId": "6b887101-79b5-4a6d-ce83-48fb5c0e93ba"
      },
      "source": [
        "characters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Jess Day', 'Julia Cleary', 'jess2', 'jess1']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnikmV16nYmf"
      },
      "source": [
        "# Step 3: Meta info / other tags\n",
        "If I wanted to manually add tags like which season, or maybe find a way to use the images themselves to create some tags for them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoOgPjvmolx7"
      },
      "source": [
        "Using the APIs to check the subtitles to the episode/season number"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQAjsPqP84J4"
      },
      "source": [
        "import requests\n",
        "def find_episode_season(subtitle):\n",
        "  # tweak function retries\n",
        "  retries = 4\n",
        "  while (retries > 0):\n",
        "    payload = {\n",
        "        'subtitle': subtitle\n",
        "    }\n",
        "    result = requests.post('/api/subtitles/search', json=payload)\n",
        "    if result.status_code == 200:\n",
        "      break\n",
        "    retries = retries - 1\n",
        "  return result.content.episode, result.content.season\n",
        "\n",
        "episode, season = find_episode_season(data['subtitle'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ_8DqG254kn"
      },
      "source": [
        "Let us look at the filename to figure out when I screenshotted it for linking to the season,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRbLTKyfoQ-0"
      },
      "source": [
        "from datetime import datetime\n",
        "TIMESTAMP_FORMAT = '%Y-%m-%d %I.%M.%S%p'\n",
        "\n",
        "endtime_season1 = datetime.strptime(\"2021-07-08 11.07.00PM\", TIMESTAMP_FORMAT)\n",
        "endtime_season2 = datetime.strptime(\"2021-07-27 9.15.00PM\", TIMESTAMP_FORMAT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_JAa7gH85Sl"
      },
      "source": [
        "# test = \"Screenshot2021-09-17at6.22.00PM_iki64j.jpg\"\n",
        "def fetch_timestamp(filename):\n",
        "  begin = 10 # skipping the words screenshot\n",
        "  end = -1\n",
        "  if filename.find('PM') != -1:\n",
        "    end = filename.find('PM')\n",
        "  else:\n",
        "    end = filename.find('AM')\n",
        "  if end == -1:\n",
        "    return\n",
        "  end = end + 2\n",
        "  timestamp = filename[begin:end]\n",
        "  timestamp = timestamp.replace('at', ' ')\n",
        "  return timestamp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYJ3fCRVj2fo"
      },
      "source": [
        "def map_season(timestamp):\n",
        "  timestamp = datetime.strptime(timestamp, TIMESTAMP_FORMAT)\n",
        "  if timestamp > endtime_season2:\n",
        "    return 3\n",
        "  if timestamp > endtime_season1:\n",
        "    return 2\n",
        "  return 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML0DQLPCAkLM"
      },
      "source": [
        "data['timestamp'] = fetch_timestamp(data['filename'])\n",
        "data['season'] = map_season(data['timestamp'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBF5FI9QFoSn"
      },
      "source": [
        "# Step 4: Append to dataset\n",
        "Let us for now put these values in a file with each dict as a row"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bymQwWPPcb32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd79ad9f-f028-4b1f-df60-1c4c3982f640"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'characters': ['Jess Day', 'Julia Cleary', 'jess2', 'jess1'],\n",
              " 'filename': 'Screenshot2021-09-17at6.29.04PM_a4vitu.jpg',\n",
              " 'imageLink': 'https://res.cloudinary.com/dw4ieof1c/image/upload/v1632050494/new-girl/batch20/Screenshot2021-07-07at11.15.22PM_tkl8tu.jpg',\n",
              " 'season': 3,\n",
              " 'subtitle': 'NA',\n",
              " 'timestamp': '2021-09-17 6.29.04PM'}"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5fPyQkcF3Y2"
      },
      "source": [
        "import json\n",
        "with open('new-girl-dataset.json', 'w') as fp:\n",
        "    json.dump(data, fp)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}